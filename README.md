# FSTT-DA
Few-Shot Test-Time Domain Adaptation

# Prompt_TTA
Prompting for Test-time Adaptation


##  Quickstart

```bash
# Install requirements
pip install -r requirements.txt

# Download & Copy CLIP's pretrained weights from
/home/ligu/projects/prompt_tta_sam_iclr2024/pretrained/openai_clip

# Run train script with the default config
python train.py
```


<br>

## Project Structure

The directory structure of new project looks like this:

Reference: [lightning-hydra-template](https://github.com/ashleve/lightning-hydra-template/)

```
│
├── configs                   <- Hydra configs
│   ├── callbacks                <- Callbacks configs
│   ├── data                     <- Data configs
│   ├── debug                    <- Debugging configs
│   ├── experiment               <- Experiment configs
│   ├── extras                   <- Extra utilities configs
│   ├── hparams_search           <- Hyperparameter search configs
│   ├── hydra                    <- Hydra configs
│   ├── local                    <- Local configs
│   ├── logger                   <- Logger configs
│   ├── model                    <- Model configs
│   ├── paths                    <- Project paths configs
│   ├── trainer                  <- Trainer configs
│   │
│   ├── eval.yaml             <- Main config for evaluation
│   └── train.yaml            <- Main config for training
│
├── logs                   <- Logs generated by hydra and lightning loggers
│
├── notebooks              <- Jupyter notebooks. Naming convention is a number (for ordering),
│                             the creator's initials, and a short `-` delimited description,
│                             e.g. `1.0-jqp-initial-data-exploration.ipynb`.
│
├── scripts                <- Shell scripts
│
├── src                    <- Source code
│   ├── datasets                <- benchmark datasets
│   ├── models                  <- model components
│   ├── lightning               <- LightningModule, DataModule, Callbacks
│   ├── solver                  <- losses, solvers, schedulers
│   ├── utils                   <- Utility modules
├── train.py                    <- Run training
├── eval.py                     <- Run evaluation
│
├── .env.example              <- Example of file for storing private environment variables
├── .project-root             <- File for inferring the position of project root directory
├── requirements.txt          <- File for installing pip environment
└── README.md
```
<br>

## How to try with your custom experiment configs

**Basic workflow**
1. Write your experiment config, adding your custom configs that would override the default.
2. Run training with chosen experiment config:
   ```bash
   python train.py experiment=experiment.yaml
   ```
<br>
